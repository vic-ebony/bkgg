# D:\bkgg\mybackend\schedule_parser\utils.py
import re
import html
import logging

logger = logging.getLogger(__name__) # å‰µå»º logger

# --- Word to Digit Mapping ---
WORD_TO_DIGIT = {
    'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5,
    'six': 6, 'seven': 7, 'eight': 8, 'nine': 9, 'ten': 10, # Add more if needed
    'é›¶': 0, 'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5,
    'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
}

# ============================================================
# --- å‡½æ•¸ 1: è§£æèˆŠçš„ LINE æ ¼å¼ (æ ¼å¼ A) ---
# ============================================================
def parse_line_schedule(text):
    """
    è§£æèˆŠæ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ (ä»¥ '(æ•¸å­—)' é–‹é ­å€å¡Š)ã€‚
    è¿”å›ä¸€å€‹åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ æ˜¯ä¸€å€‹åŒ…å«è§£æä¿¡æ¯çš„å­—å…¸ã€‚
    """
    results = []
    current_animal_block = []
    lines = text.strip().split('\n')

    for line in lines:
        line = line.strip()
        if not line: continue # è·³éç©ºè¡Œ

        if re.match(r'^\(\s*\d+\s*\)', line):
            if current_animal_block:
                parsed = process_animal_block(current_animal_block) # èª¿ç”¨èˆŠæ ¼å¼çš„è™•ç†å‡½æ•¸
                if parsed: results.append(parsed)
            current_animal_block = [line]
        elif current_animal_block:
            current_animal_block.append(line)

    if current_animal_block:
        parsed = process_animal_block(current_animal_block) # èª¿ç”¨æ—§æ ¼å¼çš„å¤„ç†å‡½æ•°
        if parsed: results.append(parsed)

    return results

def process_animal_block(block_lines):
    """è™•ç†èˆŠæ ¼å¼çš„å–®å€‹ç¾å®¹å¸«æ–‡å­—å€å¡Š"""
    if not block_lines: return None
    fee = None; name = None; original_name_text = ""; alias_suggestion = None
    height = None; weight = None; cup = None; intro_lines = []; time_slots_str = None
    try:
        first_line = block_lines[0]
        original_name_text = first_line # è¨˜éŒ„åŸå§‹ç¬¬ä¸€è¡Œ
        fee_match = re.search(r'^\(\s*(\d+)\s*\)', first_line)
        if fee_match:
            try: fee = int(fee_match.group(1)) * 100
            except ValueError: pass
        # ä¿®æ”¹åå­—æå–ï¼šå¾ ')' å¾Œé¢é–‹å§‹ï¼Œç›´åˆ° ğŸ‘™ æˆ–è¡Œå°¾
        name_part_match = re.search(r'\)\s*(.*?)(?:\s*ğŸ‘™|$)', first_line)
        if name_part_match:
            original_name_text_part = name_part_match.group(1).strip()
            # å˜—è©¦æå–æ‹¬è™Ÿå…§çš„åˆ¥å
            alias_match = re.search(r'[\(ï¼ˆ](.+?)[\)ï¼‰]', original_name_text_part)
            if alias_match:
                alias_content = alias_match.group(1).strip()
                if alias_content.startswith("åŸ"):
                    alias_suggestion = alias_content[1:].strip()
                else:
                    alias_suggestion = alias_content # å¦‚æœä¸æ˜¯ä»¥ "åŸ" é–‹é ­ï¼Œä¹Ÿè¨˜éŒ„ä¸‹ä¾†
                # å¾åŸå§‹åå­—éƒ¨åˆ†ç§»é™¤åˆ¥åæ‹¬è™Ÿ
                name = re.sub(r'[\(ï¼ˆ].+?[\)ï¼‰]', '', original_name_text_part).strip()
            else:
                # æ²’æœ‰æ‹¬è™Ÿåˆ¥åï¼Œç›´æ¥ä½¿ç”¨
                name = original_name_text_part

            # å¦‚æœåå­—ç‚ºç©ºï¼ˆå¯èƒ½åªæœ‰åˆ¥åï¼‰ï¼Œå˜—è©¦ä½¿ç”¨åˆ¥åä½œç‚ºåå­—
            if not name and alias_suggestion:
                 name = alias_suggestion
                 alias_suggestion = None # å› ç‚ºå®ƒè¢«ç”¨ä½œåå­—äº†
        else: # å¦‚æœé€£åå­—éƒ¨åˆ†éƒ½åŒ¹é…ä¸åˆ°
             name = None # æˆ–è¨­ç½®ä¸€å€‹é è¨­å€¼ï¼Œæˆ–æ ¹æ“šå¾ŒçºŒé‚è¼¯æ±ºå®š

        # èº«ææå–
        size_match = re.search(r'(\d{3})\s*/\s*(\d{2,3})\s*/\s*([A-Za-z\+\-]+)', first_line)
        if size_match:
            try: height = int(size_match.group(1))
            except ValueError: pass
            try: weight = int(size_match.group(2))
            except ValueError: pass
            cup = size_match.group(3).strip()

        time_found = False
        for line in block_lines[1:]:
            line_strip = line.strip()
            if line_strip.startswith('â°'):
                time_info = line_strip.replace('â°', '').strip()
                if time_info == 'ğŸˆµ': time_slots_str = "é ç´„æ»¿"
                elif time_info == 'äººåˆ°å†ç´„' or time_info.startswith('äººé“'): time_slots_str = "äººåˆ°å†ç´„"
                elif not time_info: time_slots_str = ""
                else:
                    slots = re.findall(r'\d{1,2}', time_info)
                    processed_slots = []
                    for s in slots:
                        try:
                            num = int(s)
                            internal_value = -1
                            if 12 <= num <= 23: internal_value = num
                            elif num == 24: internal_value = 100 # 24é» -> å…§éƒ¨ 100
                            elif 0 <= num <= 5: internal_value = num + 100 # 0-5é» -> å…§éƒ¨ 100-105
                            if internal_value != -1: processed_slots.append(internal_value)
                        except ValueError: continue
                    processed_slots.sort() # æ’åº
                    time_slots_str = ".".join(map(str, processed_slots))
                time_found = True
            elif not time_found: # åªæœ‰åœ¨é‚„æ²’æ‰¾åˆ°æ™‚é–“è¡Œæ™‚ï¼Œæ‰åŠ å…¥ä»‹ç´¹
                 # æ’é™¤ç‰¹å®šæ¨™èªŒé–‹é ­çš„è¡Œï¼Œä¸¦ä¸”ç¢ºä¿è¡Œä¸ç‚ºç©º
                 if not line_strip.startswith('ğŸˆ²') and not line_strip.startswith('(<') and not line_strip.startswith('(>') and line_strip:
                     intro_lines.append(line_strip)
            elif time_found and line_strip: # å¦‚æœæ‰¾åˆ°æ™‚é–“å¾Œé‚„æœ‰éç©ºè¡Œï¼Œä¹Ÿå¯èƒ½æ˜¯ä»‹ç´¹çš„ä¸€éƒ¨åˆ†
                 if not line_strip.startswith('ğŸˆ²') and not line_strip.startswith('(<') and not line_strip.startswith('(>'):
                     intro_lines.append(line_strip)

        if name: # ç¢ºä¿è§£æåˆ°äº†åå­—æ‰è¿”å›çµæœ
            # è¿”å›æ™‚å°‡ alias_suggestion è¨­ç‚º None (å¦‚æœèˆŠæ ¼å¼éœ€è¦åˆ¥åå‰‡ä¿ç•™)
            return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                    'alias_suggestion': alias_suggestion, 'height': height, 'weight': weight, # ä¿ç•™èˆŠæ ¼å¼å¯èƒ½éœ€è¦çš„åˆ¥å
                    'cup': cup, 'introduction': "\n".join(intro_lines).strip(),
                    'time_slots': time_slots_str if time_slots_str is not None else ""} # ç¢ºä¿ time_slots æœ‰å€¼
    except Exception as e:
        logger.error(f"è™•ç†èˆŠæ ¼å¼å€å¡Šæ™‚å‡ºéŒ¯: {block_lines}", exc_info=True)
        return None
    return None # å¦‚æœæ²’æœ‰åå­—æˆ–å…¶ä»–éŒ¯èª¤ï¼Œè¿”å› None

# ============================================================
# --- å‡½æ•¸ 2: è§£ææ–°çš„ "èŒ¶æ¹¯æœƒ" æ ¼å¼ (æ ¼å¼ B) ---
# ============================================================
def parse_chatanghui_schedule(text):
    """
    è§£æ "èŒ¶æ¹¯æœƒä¼‘é–’æœƒé¤¨" æ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ã€‚
    è¿”å›èˆ‡ parse_line_schedule ç›¸åŒçµæ§‹çš„åˆ—è¡¨ã€‚
    ä¿®æ­£äº†å€å¡Šåˆ†å‰²é‚è¼¯ã€‚
    """
    results = []
    lines = text.strip().split('\n')
    current_block_lines = []
    # ä¿®æ”¹å€å¡Šé–‹å§‹æ¨¡å¼ï¼šåå­—ç”¨ã€ã€‘åŒ…åœï¼Œå¾Œé¢å¯èƒ½è·Ÿè‘—æ•¸å­—è²»ç”¨
    block_start_pattern = r'^[(\s]*(?:[\w\s]+|\S+)[)\s]*ã€.+?ã€‘\s*\d+' # ç¨å¾®æ”¾å¯¬é–‹é ­ï¼Œä¸»è¦é ã€åå­—ã€‘è²»ç”¨ è­˜åˆ¥

    for line in lines:
        line_strip = line.strip()
        if not line_strip: continue # è·³éç©ºè¡Œ

        # åˆ¤æ–·æ˜¯å¦ç‚ºæ–°å€å¡Šçš„é–‹å§‹è¡Œ
        is_start_line = re.match(block_start_pattern, line_strip)

        if is_start_line:
            # å¦‚æœç•¶å‰æœ‰æ­£åœ¨è™•ç†çš„å€å¡Šï¼Œå…ˆè™•ç†æ‰
            if current_block_lines:
                parsed = process_chatanghui_block(current_block_lines) # èª¿ç”¨è™•ç†å‡½æ•¸
                if parsed: results.append(parsed)
            # é–‹å§‹æ–°çš„å€å¡Š
            current_block_lines = [line_strip]
        elif current_block_lines:
            # å¦‚æœä¸æ˜¯é–‹å§‹è¡Œï¼Œä¸”ç•¶å‰æœ‰å€å¡Šï¼Œå‰‡æ·»åŠ åˆ°ç•¶å‰å€å¡Š
            current_block_lines.append(line_strip)

    # è™•ç†æœ€å¾Œä¸€å€‹å€å¡Š
    if current_block_lines:
        parsed = process_chatanghui_block(current_block_lines) # è™•ç†æœ€å¾Œä¸€å€‹å€å¡Š
        if parsed: results.append(parsed)

    return results

def process_chatanghui_block(block_lines):
    """
    è™•ç†å–®å€‹ "èŒ¶æ¹¯æœƒä¼‘é–’æœƒé¤¨" æ ¼å¼çš„ç¾å®¹å¸«å€å¡Šã€‚
    æ›´éˆæ´»åœ°è™•ç†æ™‚æ®µã€èº«æã€ä»‹ç´¹ã€ç¦å¿Œè¡Œçš„é †åºã€‚
    æŒ‰åŸå§‹é †åºæ”¶é›†æ‰€æœ‰éçµæ§‹åŒ–ä¿¡æ¯è¡Œä½œç‚ºä»‹ç´¹ã€‚
    """
    if not block_lines: return None

    name = None; original_name_text = ""; alias_suggestion = None; fee = None
    time_slots_str = "" # åˆå§‹åŒ–ç‚ºç©ºå­—ä¸²
    height = None; weight = None; cup = None
    other_lines = [] # ç”¨æ–¼æ”¶é›†æ‰€æœ‰å…¶ä»–è¡Œ (ä»‹ç´¹ã€ç¦å¿Œç­‰)
    name_pattern_in_intro = r'ã€.+?ã€‘' # ç”¨æ–¼åˆ¤æ–·æ˜¯å¦æ„å¤–è®€åˆ°ä¸‹å€‹äººçš„åå­—è¡Œ

    # æ¨™è¨˜æŸé¡ä¿¡æ¯æ˜¯å¦å·²æ‰¾åˆ°
    time_found = False
    size_found = False

    line_index = 0
    try:
        # 1. è™•ç†ç¬¬ä¸€è¡Œ (åŒ…å«åå­—ã€XXXã€‘å’Œè²»ç”¨)
        first_line = block_lines[line_index]
        original_name_text = first_line # è¨˜éŒ„åŸå§‹ç¬¬ä¸€è¡Œ

        name_match = re.search(r'ã€(.+?)ã€‘', first_line)
        if name_match:
            name = name_match.group(1).strip()
            # è²»ç”¨é€šå¸¸åœ¨åå­—å¾Œé¢
            fee_match = re.search(r'ã€‘\s*(\d+)', first_line)
            if fee_match:
                try:
                    fee = int(fee_match.group(1)) * 100
                except ValueError:
                    logger.warning(f"Chatanghui Parser: ç„¡æ³•è§£æè²»ç”¨æ•¸å­— '{fee_match.group(1)}'")
            # å˜—è©¦æå–ç·Šè·Ÿè²»ç”¨å¾Œçš„åˆ¥å (åŸXXX) - èŒ¶æ¹¯æœƒæ ¼å¼å¯èƒ½éœ€è¦ä¿ç•™åˆ¥å
            alias_match = re.search(r'ã€‘\s*\d+\s*[\(ï¼ˆ](.+?)[\)ï¼‰]', first_line)
            if alias_match:
                 alias_raw = alias_match.group(1).strip()
                 if alias_raw.startswith("åŸ"):
                     alias_suggestion = alias_raw[1:].strip()
                 else:
                     alias_suggestion = alias_raw # é "åŸ" é–‹é ­ä¹Ÿè¨˜éŒ„
        else:
            # å¦‚æœç¬¬ä¸€è¡Œæ‰¾ä¸åˆ°ã€åå­—ã€‘ï¼Œå¯èƒ½æ ¼å¼æœ‰è®Šï¼Œè¨˜éŒ„è­¦å‘Šä¸¦è¿”å›
            logger.warning(f"Chatanghui Parser: ç„¡æ³•å¾ç¬¬ä¸€è¡Œè§£æåå­—: {first_line}")
            return None # æˆ–è€…å˜—è©¦å¾å¾ŒçºŒè¡Œè§£æï¼Œä½†ç›®å‰ç­–ç•¥æ˜¯åŸºæ–¼ç¬¬ä¸€è¡Œ

        line_index += 1 # ç§»åˆ°ä¸‹ä¸€è¡Œ

        # 2. å¾ªç’°è™•ç†å¾ŒçºŒæ‰€æœ‰è¡Œï¼Œéˆæ´»åŒ¹é…ï¼Œä¸¦æ”¶é›†å…¶ä»–è¡Œ
        while line_index < len(block_lines):
            current_line = block_lines[line_index].strip()

            # a. æª¢æŸ¥æ˜¯å¦æ„å¤–è®€å…¥äº†ä¸‹ä¸€å€‹å€å¡Šçš„é–‹å§‹è¡Œ (åŒ…å«ã€åå­—ã€‘æ¨¡å¼)
            #    (é¿å…æŠŠä¸‹å€‹äººçš„åå­—è¡Œç•¶æˆä»‹ç´¹)
            if re.search(name_pattern_in_intro, current_line) and line_index > 0:
                 logger.debug(f"åœæ­¢è™•ç†èŒ¶æ¹¯æœƒå€å¡Šï¼Œå› ç‚ºè¡Œ '{current_line}' åŒ…å«åå­—æ¨¡å¼ï¼Œå¯èƒ½æ˜¯ä¸‹ä¸€å€‹å€å¡Šçš„é–‹å§‹")
                 break # åœæ­¢è™•ç†ç•¶å‰å€å¡Š

            is_processed_structurally = False # æ¨™è¨˜ç•¶å‰è¡Œæ˜¯å¦è¢«è­˜åˆ¥ç‚ºçµæ§‹åŒ–ä¿¡æ¯

            # b. å˜—è©¦åŒ¹é…æ™‚æ®µ (å¦‚æœé‚„æ²’æ‰¾åˆ°)
            if not time_found:
                # å®Œå…¨åŒ¹é… "ğŸˆµï¸" æˆ– "ğŸˆµ"
                if current_line == 'ğŸˆµï¸' or current_line == 'ğŸˆµ':
                    time_slots_str = "é ç´„æ»¿"
                    time_found = True
                    is_processed_structurally = True
                # åŒ¹é… "äººåˆ°å†ç´„" æˆ– "äººåˆ°åœ¨ç´„"ï¼Œå¯èƒ½å¸¶æ‹¬è™Ÿèªªæ˜
                elif current_line.startswith('äººåˆ°å†ç´„') or current_line.startswith('äººåˆ°åœ¨ç´„'):
                    time_display = "äººåˆ°å†ç´„" # åŸºç¤ç‹€æ…‹å­—ä¸²
                    extra_info_match = re.search(r'[\(ï¼ˆ](.*?)[\)ï¼‰]', current_line)
                    if extra_info_match:
                        other_lines.append(f"(å‚™è¨»: {extra_info_match.group(1).strip()})") # ä½œç‚ºå‚™è¨»åŠ å…¥ä»‹ç´¹
                    time_slots_str = time_display # è¨­ç½® time_slots_str ç‚º "äººåˆ°å†ç´„"
                    time_found = True
                    is_processed_structurally = True
                # å˜—è©¦åŒ¹é…åŒ…å«æ•¸å­—çš„æ™‚æ®µè¡Œ
                elif re.search(r'\d', current_line): # åªè¦åŒ…å«æ•¸å­—å°±å¯èƒ½æ˜¯æ™‚æ®µè¡Œ
                    raw_slots = re.findall(r'\d+', current_line)
                    processed_slots = []
                    valid_time_line = False
                    for s in raw_slots:
                        try:
                            s_corrected = s[:2] if len(s) > 2 else s
                            num = int(s_corrected)
                            internal_value = -1
                            if 12 <= num <= 23: internal_value = num
                            elif num == 24: internal_value = 100
                            elif 0 <= num <= 5: internal_value = num + 100
                            if internal_value != -1:
                                processed_slots.append(internal_value)
                                valid_time_line = True
                        except ValueError: pass
                    if valid_time_line:
                         processed_slots = sorted(list(set(processed_slots))) # å»é‡ä¸¦æ’åº
                         time_slots_str = ".".join(map(str, processed_slots)) if processed_slots else ""
                         time_found = True
                         is_processed_structurally = True


            # c. å˜—è©¦åŒ¹é…èº«æ (å¦‚æœé‚„æ²’æ‰¾åˆ° ä¸” æœªè¢«è™•ç†ç‚ºæ™‚æ®µ)
            if not size_found and not is_processed_structurally:
                size_match_slash = re.match(r'^\s*(\d{3})\s*/\s*(\d{2,3})\s*/\s*([A-Za-z\+\-]+)\s*$', current_line)
                size_match_dot = re.match(r'^\s*(\d{3})\s*\.\s*(\d{2,3})\s*\.\s*([A-Za-z\+\-]+)\s*$', current_line)
                size_match = size_match_slash or size_match_dot
                if size_match:
                    try: height = int(size_match.group(1))
                    except ValueError: pass
                    try: weight = int(size_match.group(2))
                    except ValueError: pass
                    cup = size_match.group(3).strip()
                    size_found = True
                    is_processed_structurally = True


            # d. å¦‚æœç•¶å‰è¡Œæœªè¢«è­˜åˆ¥ç‚ºæ™‚æ®µæˆ–èº«æï¼Œä¸”ä¸ç‚ºç©ºï¼Œå‰‡åŠ å…¥ other_lines
            if not is_processed_structurally and current_line:
                other_lines.append(current_line)


            line_index += 1 # è™•ç†ä¸‹ä¸€è¡Œ

        # 3. å°‡æ”¶é›†åˆ°çš„æ‰€æœ‰ other_lines åˆä½µç‚ºä»‹ç´¹æ–‡æœ¬
        full_introduction = "\n".join(other_lines).strip()

        # 4. è¿”å›çµæœå­—å…¸
        return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                'alias_suggestion': alias_suggestion, 'height': height, 'weight': weight, # ä¿ç•™èŒ¶æ¹¯æœƒå¯èƒ½éœ€è¦çš„åˆ¥å
                'cup': cup, 'introduction': full_introduction,
                'time_slots': time_slots_str}

    except Exception as e:
        logger.error(f"è™•ç†èŒ¶æ¹¯æœƒå€å¡Šæ™‚å‡ºéŒ¯: {block_lines}", exc_info=True)
        return None

# ============================================================
# --- å‡½æ•¸ 3: è§£ææ–°çš„ "èŠ¯è‹‘é¤¨" æ ¼å¼ (æ ¼å¼ C) ---
# ============================================================
def parse_xinyuan_schedule(text):
    """
    è§£æ "èŠ¯è‹‘é¤¨" æ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ã€‚
    è¿”å›èˆ‡ parse_line_schedule ç›¸åŒçµæ§‹çš„åˆ—è¡¨ã€‚
    """
    results = []
    lines = text.strip().split('\n')
    current_block_lines = []
    block_start_pattern = r'^\s*ã€Š\s*\d+\s*ã€‹' # èŠ¯è‹‘é¤¨å€å¡Šé–‹å§‹æ¨¡å¼ ã€Š æ•¸å­— ã€‹

    for line in lines:
        line_strip = line.strip()
        if not line_strip: continue # è·³éç©ºè¡Œ

        is_start_line = re.match(block_start_pattern, line_strip)

        if is_start_line:
            if current_block_lines:
                parsed = process_xinyuan_block(current_block_lines) # <--- èª¿ç”¨èŠ¯è‹‘é¤¨çš„è™•ç†å‡½æ•¸
                if parsed: results.append(parsed)
            current_block_lines = [line_strip]
        elif current_block_lines:
            current_block_lines.append(line_strip)

    if current_block_lines:
        parsed = process_xinyuan_block(current_block_lines) # <--- èª¿ç”¨èŠ¯è‹‘é¤¨çš„è™•ç†å‡½æ•¸
        if parsed: results.append(parsed)

    return results

def process_xinyuan_block(block_lines):
    """
    è™•ç†å–®å€‹ "èŠ¯è‹‘é¤¨" æ ¼å¼çš„ç¾å®¹å¸«å€å¡Šã€‚
    æ›´éˆæ´»åœ°è™•ç†æ™‚æ®µã€èº«æã€ä»‹ç´¹ã€ç¦å¿Œè¡Œçš„é †åºã€‚
    ä¿®æ­£äº† "äººåˆ°å†ç´„" å¾Œçš„æ™‚é–“ç¯„åœè™•ç†ã€‚
    """
    if not block_lines: return None

    fee = None; name = None; original_name_text = ""; alias_suggestion = None # èŠ¯è‹‘æ ¼å¼ä¼¼ä¹ä¸æ˜é¡¯æœ‰åˆ¥å
    time_slots_str = ""; height = None; weight = None; cup = None
    other_lines = [] # æ”¶é›†æ‰€æœ‰éçµæ§‹åŒ–è¡Œ
    xinyuan_block_start_pattern = r'^\s*ã€Š\s*\d+\s*ã€‹' # ç”¨æ–¼åˆ¤æ–·å€å¡ŠçµæŸ

    # æ¨™è¨˜ä¿¡æ¯æ˜¯å¦å·²æ‰¾åˆ°
    time_found = False
    size_found = False

    line_index = 0
    try:
        # 1. è™•ç†ç¬¬ä¸€è¡Œ (è²»ç”¨ã€åå­—ã€å¯èƒ½çš„èº«æ)
        first_line = block_lines[line_index]
        original_name_text = first_line # è¨˜éŒ„åŸå§‹ç¬¬ä¸€è¡Œ

        # æå–è²»ç”¨
        fee_match = re.search(r'ã€Š\s*(\d+)\s*ã€‹', first_line)
        if fee_match:
            try: fee = int(fee_match.group(1)) * 100
            except ValueError: logger.warning(f"Xinyuan Parser: ç„¡æ³•è§£æè²»ç”¨ '{fee_match.group(1)}'")

        # æå–åå­—éƒ¨åˆ†ï¼šå»æ‰è²»ç”¨æ¨™ç±¤ã€(new)æ¨™ç±¤ï¼Œç›´åˆ°å¯èƒ½çš„èº«æä¿¡æ¯æˆ–è¡Œå°¾
        name_part = re.sub(r'^\s*ã€Š\s*\d+\s*ã€‹\s*(\(new\))?\s*', '', first_line).strip()

        # å˜—è©¦åœ¨åå­—éƒ¨åˆ†çµå°¾è™•æŸ¥æ‰¾èº«æä¿¡æ¯ (æ ¼å¼: 168.45.C)
        size_match_in_first = re.search(r'(\d{3}\.\d{2,3}\.[A-Za-z\+\-]+)$', name_part) # $ç¢ºä¿åœ¨çµå°¾

        if size_match_in_first:
            # å¦‚æœæ‰¾åˆ°ï¼Œåå­—æ˜¯èº«æä¿¡æ¯ä¹‹å‰çš„éƒ¨åˆ†
            name = name_part[:size_match_in_first.start()].strip()
            # è§£æèº«æ
            size_str = size_match_in_first.group(1)
            parts = size_str.split('.')
            if len(parts) == 3:
                try: height = int(parts[0])
                except ValueError: pass
                try: weight = int(parts[1])
                except ValueError: pass
                cup = parts[2].strip()
                size_found = True
        else:
             # å¦‚æœç¬¬ä¸€è¡Œæœ«å°¾æ²’æœ‰èº«æä¿¡æ¯ï¼Œå‰‡æ•´å€‹ name_part è¦–ç‚ºåå­— (å¯èƒ½éœ€è¦æ¸…ç†æœ«å°¾éå­—æ¯æ•¸å­—)
             # æ¸…ç†æ‰æœ«å°¾å¯èƒ½çš„ç¬¦è™Ÿæˆ–è¡¨æƒ…ç¬¦è™Ÿ
             name_part_cleaned = re.sub(r'[^\w\s]+$', '', name_part).strip()
             name = name_part_cleaned

        if not name:
             logger.warning(f"Xinyuan Parser: ç„¡æ³•å¾ '{first_line}' è§£æåå­—")
             return None # å¦‚æœé€£åå­—éƒ½è§£æä¸åˆ°ï¼Œå‰‡æ­¤å€å¡Šç„¡æ•ˆ

        line_index += 1 # ç§»åˆ°ä¸‹ä¸€è¡Œ

        # 2. å¾ªç’°è™•ç†å¾ŒçºŒæ‰€æœ‰è¡Œ
        while line_index < len(block_lines):
            current_line = block_lines[line_index].strip()

            # a. æª¢æŸ¥æ˜¯å¦æ˜¯ä¸‹ä¸€å€å¡Šçš„é–‹å§‹è¡Œ
            if re.match(xinyuan_block_start_pattern, current_line):
                 break # åœæ­¢è™•ç†ç•¶å‰å€å¡Š

            is_processed_structurally = False # æ¨™è¨˜ç•¶å‰è¡Œæ˜¯å¦è¢«è­˜åˆ¥ç‚ºçµæ§‹åŒ–ä¿¡æ¯

            # b. å˜—è©¦åŒ¹é…æ™‚æ®µ (å¦‚æœé‚„æ²’æ‰¾åˆ°)
            if not time_found:
                if current_line == 'ğŸˆµï¸' or current_line == 'ğŸˆµ':
                    time_slots_str = "é ç´„æ»¿"
                    time_found = True
                    is_processed_structurally = True
                elif current_line.startswith('äººåˆ°å†ç´„') or current_line.startswith('äººåˆ°åœ¨ç´„'):
                    time_display = "äººåˆ°å†ç´„"
                    extra_info_match = re.search(r'[\(ï¼ˆ](.*?)[\)ï¼‰]', current_line)
                    if extra_info_match:
                        other_lines.append(f"(å‚™è¨»: {extra_info_match.group(1).strip()})")
                    time_slots_str = time_display # è¨­ç½®ç‚º "äººåˆ°å†ç´„"
                    time_found = True
                    is_processed_structurally = True
                elif re.search(r'\d', current_line): # åªè¦åŒ…å«æ•¸å­—å°±å¯èƒ½æ˜¯æ™‚æ®µè¡Œ
                    cleaned_time_info = re.sub(r'[^\d-]+', '', current_line)
                    slots = cleaned_time_info.split('-') # æŒ‰ '-' åˆ†å‰²
                    processed_slots = []; valid_time_line = False
                    for s in slots:
                        s_num_part = re.search(r'\d+', s) # æå–æ•¸å­—éƒ¨åˆ†
                        if s_num_part:
                            s_val = s_num_part.group(0)
                            try:
                                s_corrected = s_val[:2] if len(s_val) > 2 else s_val
                                num = int(s_corrected)
                                internal_value = -1
                                if 12 <= num <= 23: internal_value = num
                                elif num == 24: internal_value = 100
                                elif 0 <= num <= 5: internal_value = num + 100
                                if internal_value != -1:
                                    processed_slots.append(internal_value); valid_time_line = True
                            except ValueError: pass # å¿½ç•¥ç„¡æ³•è½‰æ›çš„æ•¸å­—
                    if valid_time_line:
                         processed_slots = sorted(list(set(processed_slots))) # å»é‡ä¸¦æ’åº
                         time_slots_str = ".".join(map(str, processed_slots)) if processed_slots else ""
                         time_found = True
                         is_processed_structurally = True


            # c. å˜—è©¦åŒ¹é…èº«æ (å¦‚æœç¬¬ä¸€è¡Œæ²’æ‰¾åˆ° ä¸” æœªè¢«è™•ç†ç‚ºæ™‚æ®µ)
            if not size_found and not is_processed_structurally:
                size_match = re.match(r'^\s*(\d{3})\s*\.\s*(\d{2,3})\s*\.\s*([A-Za-z\+\-]+)\s*$', current_line)
                if size_match:
                    try: height = int(size_match.group(1))
                    except ValueError: pass
                    try: weight = int(size_match.group(2))
                    except ValueError: pass
                    cup = size_match.group(3).strip()
                    size_found = True
                    is_processed_structurally = True


            # d. å¦‚æœæœªè¢«çµæ§‹åŒ–è™•ç†ï¼Œå‰‡åŠ å…¥ other_lines
            if not is_processed_structurally and current_line:
                other_lines.append(current_line)

            line_index += 1 # è™•ç†ä¸‹ä¸€è¡Œ

        # 3. åˆä½µä»‹ç´¹æ–‡æœ¬
        full_introduction = "\n".join(other_lines).strip()

        # 4. è¿”å›çµæœ
        return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                'alias_suggestion': None, # èŠ¯è‹‘æ ¼å¼ä¸æ˜é¡¯æœ‰åˆ¥å
                'height': height, 'weight': weight, 'cup': cup,
                'introduction': full_introduction, 'time_slots': time_slots_str}

    except Exception as e:
        logger.error(f"è™•ç†èŠ¯è‹‘é¤¨å€å¡Šæ™‚å‡ºéŒ¯: {block_lines}", exc_info=True)
        return None

# ============================================================
# --- å‡½æ•¸ 4: è§£ææ–°çš„ "æ‰‹ä¸­æƒ…" æ ¼å¼ (æ ¼å¼ D) ---
# ============================================================
def parse_shouzhongqing_schedule(text):
    """
    è§£æ "æ‰‹ä¸­æƒ…" æ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ã€‚
    è¿”å›èˆ‡ parse_line_schedule ç›¸åŒçµæ§‹çš„åˆ—è¡¨ã€‚
    """
    results = []
    lines = text.strip().split('\n')
    current_block_lines = []
    # æ‰‹ä¸­æƒ…å€å¡Šé–‹å§‹æ¨¡å¼ï¼š(æ•¸å­—)
    block_start_pattern = r'^\(\s*\d+\s*\)'

    for line in lines:
        line_strip = line.strip()
        if not line_strip: continue # è·³éç©ºè¡Œ

        if re.match(block_start_pattern, line_strip):
            if current_block_lines:
                parsed = process_shouzhongqing_block(current_block_lines) # <--- èª¿ç”¨æ‰‹ä¸­æƒ…çš„è™•ç†å‡½æ•¸
                if parsed: results.append(parsed)
            current_block_lines = [line_strip]
        elif current_block_lines:
            current_block_lines.append(line_strip)

    if current_block_lines:
        parsed = process_shouzhongqing_block(current_block_lines) # <--- èª¿ç”¨æ‰‹ä¸­æƒ…çš„è™•ç†å‡½æ•¸
        if parsed: results.append(parsed)

    return results

def process_shouzhongqing_block(block_lines):
    """è™•ç†å–®å€‹ "æ‰‹ä¸­æƒ…" æ ¼å¼çš„ç¾å®¹å¸«å€å¡Š"""
    if not block_lines: return None

    fee = None; name = None; original_name_text = ""; alias_suggestion = None
    time_slots_str = ""; height = None; weight = None; cup = None
    other_lines = [] # æ”¶é›†æ‰€æœ‰éçµæ§‹åŒ–è¡Œ
    shouzhongqing_block_start_pattern = r'^\(\s*\d+\s*\)' # ç”¨æ–¼åˆ¤æ–·å€å¡ŠçµæŸ
    # åˆ¥åæ¨¡å¼ï¼šåŒ¹é… (åŸXXX) æˆ– (85XXX) ç­‰ - æ‰‹ä¸­æƒ…æ ¼å¼å¯èƒ½éœ€è¦ä¿ç•™åˆ¥å
    alias_pattern = r'[\(ï¼ˆ](åŸ.+?|85.+?)[\)ï¼‰]'

    # æ¨™è¨˜ä¿¡æ¯æ˜¯å¦å·²æ‰¾åˆ°
    time_found = False
    size_found = False

    line_index = 0
    try:
        # 1. è™•ç†ç¬¬ä¸€è¡Œ (è²»ç”¨ã€åå­—ã€åˆ¥åã€å¯èƒ½çš„èº«æ)
        first_line = block_lines[line_index]
        original_name_text = first_line # è¨˜éŒ„åŸå§‹ç¬¬ä¸€è¡Œ

        # æå–è²»ç”¨
        fee_match = re.search(r'^\(\s*(\d+)\s*\)', first_line)
        if fee_match:
            try: fee = int(fee_match.group(1)) * 100
            except ValueError: logger.warning(f"Shouzhongqing Parser: ç„¡æ³•è§£æè²»ç”¨ '{fee_match.group(1)}'")

        # æå–åå­—éƒ¨åˆ†ï¼šå¾ ')' å¾Œé¢é–‹å§‹ï¼Œç›´åˆ° ğŸ‘™ æˆ–è¡Œå°¾
        name_part_match = re.search(r'\)\s*(.*?)(?:\s*ğŸ‘™|$)', first_line)
        if name_part_match:
            name_part = name_part_match.group(1).strip()

            # å˜—è©¦å¾åå­—éƒ¨åˆ†æå–åˆ¥å
            alias_match = re.search(alias_pattern, name_part)
            if alias_match:
                 alias_content = alias_match.group(1).strip()
                 if alias_content.startswith("åŸ"):
                      alias_suggestion = alias_content[1:].strip()
                 else:
                      alias_suggestion = alias_content # é "åŸ" é–‹é ­ä¹Ÿç®—åˆ¥å
                 name = re.sub(alias_pattern, '', name_part).strip()
            else:
                name = name_part

            if not name and alias_suggestion:
                 name = alias_suggestion
                 alias_suggestion = None

            # å˜—è©¦åœ¨ç¬¬ä¸€è¡Œçµå°¾è™•æŸ¥æ‰¾èº«æä¿¡æ¯ (åœ¨ ğŸ‘™ å¾Œé¢ï¼Œæ ¼å¼: 168 / 45 / C)
            size_match_in_first = re.search(r'ğŸ‘™\s*(\d{3})\s*/\s*(\d{2,3})\s*/\s*([A-Za-z\+\-]+)', first_line)
            if size_match_in_first:
                try: height = int(size_match_in_first.group(1))
                except ValueError: pass
                try: weight = int(size_match_in_first.group(2))
                except ValueError: pass
                cup = size_match_in_first.group(3).strip()
                size_found = True
        else:
             logger.warning(f"Shouzhongqing Parser: ç„¡æ³•å¾ '{first_line}' è§£æåå­—éƒ¨åˆ†")
             name = None # è¨­ç‚º None

        if not name:
             logger.warning(f"Shouzhongqing Parser: ç„¡æ³•å¾ '{first_line}' è§£æåå­—")
             return None # åå­—æ˜¯å¿…é ˆçš„

        line_index += 1 # ç§»åˆ°ä¸‹ä¸€è¡Œ

        # 2. å¾ªç’°è™•ç†å¾ŒçºŒæ‰€æœ‰è¡Œ
        while line_index < len(block_lines):
            current_line = block_lines[line_index].strip()

            # a. æª¢æŸ¥æ˜¯å¦æ˜¯ä¸‹ä¸€å€å¡Šçš„é–‹å§‹è¡Œ
            if re.match(shouzhongqing_block_start_pattern, current_line):
                 break # åœæ­¢è™•ç†ç•¶å‰å€å¡Š

            is_processed_structurally = False # æ¨™è¨˜ç•¶å‰è¡Œæ˜¯å¦è¢«è­˜åˆ¥ç‚ºçµæ§‹åŒ–ä¿¡æ¯

            # b. å˜—è©¦åŒ¹é…æ™‚æ®µ (å¦‚æœé‚„æ²’æ‰¾åˆ°ï¼Œä»¥ â° é–‹é ­)
            if not time_found and current_line.startswith('â°'):
                time_info = current_line.replace('â°', '').strip()
                if time_info == 'ğŸˆµ' or time_info == 'ğŸˆµï¸':
                    time_slots_str = "é ç´„æ»¿"
                elif time_info == 'äººåˆ°å†ç´„':
                    time_slots_str = "äººåˆ°å†ç´„"
                elif not time_info: # å¯èƒ½æ˜¯ç©ºçš„ â°
                    time_slots_str = ""
                else:
                    slots = re.findall(r'\d+', time_info) # ç›´æ¥æå–æ‰€æœ‰æ•¸å­—
                    processed_slots = []
                    for s in slots:
                        try:
                            num = int(s); internal_value = -1
                            if 12 <= num <= 23: internal_value = num
                            elif num == 24: internal_value = 100
                            elif 0 <= num <= 5: internal_value = num + 100
                            if internal_value != -1: processed_slots.append(internal_value)
                        except ValueError: pass
                    processed_slots = sorted(list(set(processed_slots))) # å»é‡ä¸¦æ’åº
                    time_slots_str = ".".join(map(str, processed_slots)) if processed_slots else ""
                time_found = True
                is_processed_structurally = True


            # c. å˜—è©¦åŒ¹é…èº«æ (å¦‚æœç¬¬ä¸€è¡Œæ²’æ‰¾åˆ° ä¸” æœªè¢«è™•ç†ç‚ºæ™‚æ®µ)
            if not size_found and not is_processed_structurally:
                size_match = re.match(r'^\s*(\d{3})\s*/\s*(\d{2,3})\s*/\s*([A-Za-z\+\-]+)\s*$', current_line)
                if size_match:
                    try: height = int(size_match.group(1))
                    except ValueError: pass
                    try: weight = int(size_match.group(2))
                    except ValueError: pass
                    cup = size_match.group(3).strip()
                    size_found = True
                    is_processed_structurally = True


            # d. å¦‚æœæœªè¢«çµæ§‹åŒ–è™•ç†ï¼Œå‰‡åŠ å…¥ other_lines
            if not is_processed_structurally and current_line:
                # æª¢æŸ¥ä»‹ç´¹è¡Œä¸­æ˜¯å¦åŒ…å«åˆ¥åï¼Œå¦‚æœç¬¬ä¸€è¡Œæ²’æ‰¾åˆ°ï¼Œå‰‡è¨˜éŒ„
                if not alias_suggestion:
                    alias_match_intro = re.search(alias_pattern, current_line)
                    if alias_match_intro:
                        alias_content = alias_match_intro.group(1).strip()
                        if alias_content.startswith("åŸ"):
                            alias_suggestion = alias_content[1:].strip()
                        else:
                            alias_suggestion = alias_content
                other_lines.append(current_line)

            line_index += 1 # è™•ç†ä¸‹ä¸€è¡Œ

        # 3. åˆä½µä»‹ç´¹æ–‡æœ¬
        full_introduction = "\n".join(other_lines).strip()

        # 4. è¿”å›çµæœ
        return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                'alias_suggestion': alias_suggestion, 'height': height, 'weight': weight, # ä¿ç•™æ‰‹ä¸­æƒ…å¯èƒ½éœ€è¦çš„åˆ¥å
                'cup': cup, 'introduction': full_introduction,
                'time_slots': time_slots_str}

    except Exception as e:
        logger.error(f"è™•ç†æ‰‹ä¸­æƒ…å€å¡Šæ™‚å‡ºéŒ¯: {block_lines}", exc_info=True)
        return None

# ============================================================
# --- å‡½æ•¸ 5: è§£ææ–°çš„ "å¯¶å¯å¤¢" æ ¼å¼ (æ ¼å¼ F) ---
# ============================================================
def parse_pokemon_schedule(text):
    """
    è§£æ "å¯¶å¯å¤¢" æ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ã€‚
    è¿”å›èˆ‡ parse_line_schedule ç›¸åŒçµæ§‹çš„åˆ—è¡¨ã€‚
    """
    results = []
    lines = text.strip().split('\n')
    current_block_lines = []
    # å¯¶å¯å¤¢å€å¡Šé–‹å§‹æ¨¡å¼ï¼šä»¥ (æ•¸å­—) é–‹é ­ï¼Œå…è¨±åŒ…å« ğŸ†• æˆ–å…¶ä»–ç¬¦è™Ÿ
    block_start_pattern = r'^\s*(?:ğŸ†•|new|\(new\))?\s*\(\s*\d+\s*\)' # æ›´å¯¬é¬†çš„åŒ¹é…é–‹é ­

    for line in lines:
        line_strip = line.strip()
        if not line_strip: continue # è·³éç©ºè¡Œ

        if re.match(block_start_pattern, line_strip):
            if current_block_lines:
                parsed = process_pokemon_block(current_block_lines) # <--- èª¿ç”¨å¯¶å¯å¤¢çš„è™•ç†å‡½æ•¸
                if parsed: results.append(parsed)
            current_block_lines = [line_strip]
        elif current_block_lines:
            current_block_lines.append(line_strip)

    if current_block_lines:
        parsed = process_pokemon_block(current_block_lines) # <--- èª¿ç”¨å¯¶å¯å¤¢çš„è™•ç†å‡½æ•¸
        if parsed: results.append(parsed)

    return results

def process_pokemon_block(block_lines):
    """è™•ç†å–®å€‹ "å¯¶å¯å¤¢" æ ¼å¼çš„ç¾å®¹å¸«å€å¡Š"""
    if not block_lines: return None

    fee = None; name = None; original_name_text = ""; alias_suggestion = None
    time_slots_str = ""; height = None; weight = None; cup = None
    other_lines = [] # æ”¶é›†æ‰€æœ‰éçµæ§‹åŒ–è¡Œ
    pokemon_block_start_pattern = r'^\s*(?:ğŸ†•|new|\(new\))?\s*\(\s*\d+\s*\)'
    # åˆ¥åæ¨¡å¼ - å¯¶å¯å¤¢æ ¼å¼å¯èƒ½éœ€è¦ä¿ç•™åˆ¥å
    alias_pattern = r'[\(ï¼ˆ](åŸ.+?|85.+?|èŒ¶æ¹¯æœƒ.+?)[\)ï¼‰]'

    # æ¨™è¨˜ä¿¡æ¯æ˜¯å¦å·²æ‰¾åˆ°
    time_found = False
    size_found = False

    line_index = 0
    try:
        # 1. è™•ç†ç¬¬ä¸€è¡Œ (è²»ç”¨ã€åå­—ã€åˆ¥åã€å¯èƒ½çš„èº«æ)
        first_line = block_lines[line_index]
        original_name_text = first_line # è¨˜éŒ„åŸå§‹ç¬¬ä¸€è¡Œ

        fee_match = re.search(r'\(\s*(\d+)\s*\)', first_line)
        if fee_match:
            try: fee = int(fee_match.group(1)) * 100
            except ValueError: logger.warning(f"Pokemon Parser: ç„¡æ³•è§£æè²»ç”¨ '{fee_match.group(1)}'")

        name_part = re.sub(r'^\s*(?:ğŸ†•|new|\(new\))?\s*\(\s*\d+\s*\)\s*', '', first_line).strip()
        size_match_in_first = re.search(r'(\d{3}\s*\.\s*\d{2,3}\s*\.\s*[A-Za-z\+\-]+)', name_part)

        if size_match_in_first:
            name = name_part[:size_match_in_first.start()].strip()
            size_str = size_match_in_first.group(1)
            parts = re.split(r'\s*\.\s*', size_str) # ç”¨é»åˆ†å‰²ï¼Œå…è¨±ç©ºæ ¼
            if len(parts) == 3:
                try: height = int(parts[0])
                except ValueError: pass
                try: weight = int(parts[1])
                except ValueError: pass
                cup = parts[2].strip()
                size_found = True
        else:
             alias_match = re.search(alias_pattern, name_part)
             if alias_match:
                 alias_content = alias_match.group(1).strip()
                 if alias_content.startswith("åŸ"):
                      alias_suggestion = alias_content[1:].strip()
                 else:
                      alias_suggestion = alias_content
                 name = re.sub(alias_pattern, '', name_part).strip()
             else:
                 name = re.sub(r'[^\w\s]+$', '', name_part).strip()

        if not name and alias_suggestion:
            name = alias_suggestion
            alias_suggestion = None

        if not name:
             logger.warning(f"Pokemon Parser: ç„¡æ³•å¾ '{first_line}' è§£æåå­—")
             return None # åå­—æ˜¯å¿…é ˆçš„

        line_index += 1 # ç§»åˆ°ä¸‹ä¸€è¡Œ

        # 2. å¾ªç’°è™•ç†å¾ŒçºŒæ‰€æœ‰è¡Œ
        while line_index < len(block_lines):
            current_line = block_lines[line_index].strip()

            if re.match(pokemon_block_start_pattern, current_line):
                 break # åœæ­¢è™•ç†ç•¶å‰å€å¡Š

            is_processed_structurally = False # æ¨™è¨˜ç•¶å‰è¡Œæ˜¯å¦è¢«è­˜åˆ¥ç‚ºçµæ§‹åŒ–ä¿¡æ¯

            # b. å˜—è©¦åŒ¹é…æ™‚æ®µ (å¦‚æœé‚„æ²’æ‰¾åˆ°ï¼Œä»¥ ğŸˆ³ é–‹é ­ æˆ– å–®ç¨ç‚º ğŸˆµ)
            if not time_found:
                if current_line.startswith('ğŸˆ³'):
                    time_info = current_line.replace('ğŸˆ³', '').strip()
                    if time_info == 'ğŸˆµ' or time_info == 'ğŸˆµï¸':
                        time_slots_str = "é ç´„æ»¿"
                    elif not time_info: # å¯èƒ½æ˜¯ç©ºçš„ ğŸˆ³
                        time_slots_str = ""
                    else:
                        slots = re.findall(r'\d+', time_info) # ç›´æ¥æå–æ‰€æœ‰æ•¸å­—
                        processed_slots = []
                        for s in slots:
                            try:
                                num = int(s); internal_value = -1
                                if 12 <= num <= 23: internal_value = num
                                elif num == 24: internal_value = 100
                                elif 0 <= num <= 5: internal_value = num + 100
                                if internal_value != -1: processed_slots.append(internal_value)
                            except ValueError: pass
                        processed_slots = sorted(list(set(processed_slots))) # å»é‡ä¸¦æ’åº
                        time_slots_str = ".".join(map(str, processed_slots)) if processed_slots else ""
                    time_found = True
                    is_processed_structurally = True
                elif current_line == 'ğŸˆµ' or current_line == 'ğŸˆµï¸': # è™•ç†å–®ç¨çš„ ğŸˆµ è¡Œ
                     time_slots_str = "é ç´„æ»¿"
                     time_found = True
                     is_processed_structurally = True


            # c. å˜—è©¦åŒ¹é…èº«æ (å¦‚æœç¬¬ä¸€è¡Œæ²’æ‰¾åˆ° ä¸” æœªè¢«è™•ç†ç‚ºæ™‚æ®µ)
            if not size_found and not is_processed_structurally:
                size_match = re.match(r'^\s*(\d{3})\s*\.\s*(\d{2,3})\s*\.\s*([A-Za-z\+\-]+)\s*$', current_line)
                if size_match:
                    try: height = int(size_match.group(1))
                    except ValueError: pass
                    try: weight = int(size_match.group(2))
                    except ValueError: pass
                    cup = size_match.group(3).strip()
                    size_found = True
                    is_processed_structurally = True


            # d. å¦‚æœæœªè¢«çµæ§‹åŒ–è™•ç†ï¼Œå‰‡åŠ å…¥ other_lines
            if not is_processed_structurally and current_line:
                 # æª¢æŸ¥ä»‹ç´¹è¡Œä¸­æ˜¯å¦åŒ…å«åˆ¥åï¼Œå¦‚æœç¬¬ä¸€è¡Œæ²’æ‰¾åˆ°ï¼Œå‰‡è¨˜éŒ„
                 if not alias_suggestion:
                     alias_match_intro = re.search(alias_pattern, current_line)
                     if alias_match_intro:
                         alias_content = alias_match_intro.group(1).strip()
                         if alias_content.startswith("åŸ"):
                             alias_suggestion = alias_content[1:].strip()
                         else:
                             alias_suggestion = alias_content
                 other_lines.append(current_line)


            line_index += 1 # è™•ç†ä¸‹ä¸€è¡Œ

        # 3. åˆä½µä»‹ç´¹æ–‡æœ¬
        full_introduction = "\n".join(other_lines).strip()

        # 4. è¿”å›çµæœ
        return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                'alias_suggestion': alias_suggestion, 'height': height, 'weight': weight, # ä¿ç•™å¯¶å¯å¤¢å¯èƒ½éœ€è¦çš„åˆ¥å
                'cup': cup, 'introduction': full_introduction,
                'time_slots': time_slots_str}

    except Exception as e:
        logger.error(f"è™•ç†å¯¶å¯å¤¢å€å¡Šæ™‚å‡ºéŒ¯: {block_lines}", exc_info=True)
        return None


# ============================================================
# --- *** å‡½æ•¸ 6: è§£ææ–°çš„ "æ„›å¯¶é¤¨" æ ¼å¼ (æ ¼å¼ G - Aibao) *** ---
# ============================================================
# --- *** ä½¿ç”¨å„ªåŒ–å¾Œçš„ parse_aibao_schedule *** ---
def parse_aibao_schedule(text):
    """
    è§£æ "æ„›å¯¶é¤¨" æ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ã€‚
    è¿”å›èˆ‡ parse_line_schedule ç›¸åŒçµæ§‹çš„åˆ—è¡¨ã€‚
    æ¡ç”¨æ›´å¥å£¯çš„å€å¡Šåˆ†å‰²é‚è¼¯ã€‚
    """
    results = []
    lines = text.strip().split('\n')
    if not lines:
        return results

    # æ„›å¯¶å€å¡Šé–‹å§‹æ¨¡å¼ï¼š(æ•¸å­—) æˆ– (new)(æ•¸å­—)ï¼Œè€ƒæ…®å‰å¾Œç©ºæ ¼å’Œå…¨åŠå½¢æ‹¬è™Ÿ
    block_start_pattern = r'^\s*(?:\(new\)|ï¼ˆnewï¼‰)?\s*[\(ï¼ˆ]\s*\d+\s*[\)ï¼‰]'
    start_indices = []

    # 1. æ‰¾åˆ°æ‰€æœ‰å€å¡Šé–‹å§‹è¡Œçš„ç´¢å¼•
    for i, line in enumerate(lines):
        line_strip = line.strip()
        if not line_strip: continue # è·³éç©ºè¡Œ
        if re.match(block_start_pattern, line_strip):
            start_indices.append(i)

    if not start_indices:
        logger.warning("Aibao Parser: No block start lines found using pattern: %s", block_start_pattern)
        # ä½œç‚ºå‚™ç”¨ï¼Œå˜—è©¦ä¸€å€‹æ›´ç°¡å–®çš„æ¨¡å¼ï¼Œåƒ…æŸ¥æ‰¾è¡Œé¦–çš„ (æ•¸å­—) æˆ– ï¼ˆæ•¸å­—ï¼‰
        block_start_pattern_fallback = r'^\s*[\(ï¼ˆ]\s*\d+\s*[\)ï¼‰]'
        for i, line in enumerate(lines):
             line_strip = line.strip()
             if not line_strip: continue
             if re.match(block_start_pattern_fallback, line_strip):
                  start_indices.append(i)
        if not start_indices:
             logger.error("Aibao Parser: Still no block start lines found even with fallback pattern.")
             return results # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œè¿”å›ç©º

    # 2. æ ¹æ“šé–‹å§‹è¡Œç´¢å¼•åˆ†å‰²å€å¡Š
    num_blocks = len(start_indices)
    for i in range(num_blocks):
        start_index = start_indices[i]
        # çµæŸç´¢å¼•æ˜¯ä¸‹ä¸€å€‹é–‹å§‹è¡Œçš„ç´¢å¼•ï¼Œæˆ–è€…æ˜¯åˆ—è¡¨çš„æœ«å°¾
        end_index = start_indices[i+1] if (i + 1) < num_blocks else len(lines)

        # ç²å–ç•¶å‰å€å¡Šçš„æ‰€æœ‰è¡Œ (å¾ start_index åˆ° end_index ä¹‹å‰)
        current_block_lines = [lines[j] for j in range(start_index, end_index)]

        # éæ¿¾æ‰ç´”ç²¹çš„ç©ºè¡Œæˆ–åªæœ‰ç©ºæ ¼çš„è¡Œ
        current_block_lines_cleaned = [line for line in current_block_lines if line.strip()]

        if current_block_lines_cleaned:
            parsed = process_aibao_block(current_block_lines_cleaned) # <--- èª¿ç”¨æ„›å¯¶é¤¨çš„è™•ç†å‡½æ•¸
            if parsed:
                results.append(parsed)
            else:
                logger.warning(f"Aibao Parser: Failed to process block starting at line {start_index+1}: {current_block_lines_cleaned[0] if current_block_lines_cleaned else 'EMPTY'}")
        else:
            logger.debug(f"Aibao Parser: Skipping empty block found between lines {start_index} and {end_index}")

    return results

# --- process_aibao_block å‡½æ•¸ (ç§»é™¤æ‹¬è™Ÿæ¸…ç†ï¼Œåˆ¥åè¦–ç‚ºä»‹ç´¹) ---
def process_aibao_block(block_lines):
    """è™•ç†å–®å€‹ "æ„›å¯¶é¤¨" æ ¼å¼çš„ç¾å®¹å¸«å€å¡Šï¼ˆç§»é™¤æ‹¬è™Ÿæ¸…ç†ï¼Œåˆ¥åè¦–ç‚ºä»‹ç´¹ï¼‰"""
    if not block_lines: return None

    fee = None; name = None; original_name_text = ""; # No alias_suggestion needed
    time_slots_str = ""; height = None; weight = None; cup = None
    other_lines = [] # æ”¶é›†ä»‹ç´¹è¡Œ

    # Patterns
    size_pattern_for_match = r'\(?\s*(\d{3})\s*[./\s]\s*(\d{2,3})\s*[./\s]\s*([A-Za-z\+\-]+)\s*\)?' # Adjusted to handle space/dot/slash
    # Patterns to check if a line *only* contains specific info
    size_only_pattern = r'^\s*' + r'\(?\s*\d{3}\s*[./\s]\s*\d{2,3}\s*[./\s]\s*[A-Za-z\+\-]+\s*\)?' + r'\s*$'
    time_only_pattern = r'^\s*(?:ğŸˆµ+|[\d\.\s]+)\s*$'

    # Flags
    time_found = False
    size_found = False # Tracks if size info has been found *anywhere* in the block

    try:
        # 1. Process First Line (Fee, Name, Potential Time)
        first_line = block_lines[0].strip()
        original_name_text = first_line

        fee_match = re.search(r'[\(ï¼ˆ]\s*(\d+)\s*[\)ï¼‰]', first_line)
        if fee_match:
            try: fee = int(fee_match.group(1)) * 100
            except ValueError: logger.warning(f"Aibao Parser: Cannot parse fee '{fee_match.group(1)}' from '{first_line}'")

        content_part = re.sub(r'^\s*(?:\(new\)|ï¼ˆnewï¼‰)?\s*[\(ï¼ˆ]\s*\d+\s*[\)ï¼‰]\s*', '', first_line).strip()
        time_match = re.search(r'((?:[\d]+\.?)+|ğŸˆµ+)\s*$', content_part)

        if time_match:
            name_part = content_part[:time_match.start()].strip()
            time_info = time_match.group(1).strip()
            if 'ğŸˆµ' in time_info:
                 time_slots_str = "é ç´„æ»¿"
            else:
                 slots = re.findall(r'\d+', time_info)
                 processed_slots = []; valid_time_line_f1 = False
                 for s in slots:
                     try:
                         num = int(s); internal_value = -1
                         if 12 <= num <= 23: internal_value = num
                         elif num == 24: internal_value = 100
                         elif 0 <= num <= 11: internal_value = num + 100
                         if internal_value != -1: processed_slots.append(internal_value); valid_time_line_f1 = True
                     except ValueError: pass
                 if valid_time_line_f1:
                      processed_slots.sort(); time_slots_str = ".".join(map(str, processed_slots))
                 else: time_slots_str = ""
            time_found = True
            name = re.sub(r'\W+$', '', name_part).strip()
        else:
            name_part = content_part.strip()
            name = re.sub(r'\W+$', '', name_part).strip()

        if not name:
             logger.warning(f"Aibao Parser: Could not parse name from first line: '{first_line}'")

        # 2. Process Subsequent Lines
        for i in range(1, len(block_lines)):
            current_line = block_lines[i].strip()
            if not current_line: continue

            # --- Reset flags for the current line ---
            contains_time_this_line = False
            contains_size_this_line = False
            is_only_time = False
            is_only_size = False
            local_size_match_obj = None # Store the match object for this line

            # --- Check Time ---
            if not time_found:
                is_time_line = False # Local flag for this line
                if 'ğŸˆµ' in current_line:
                    time_slots_str = "é ç´„æ»¿"; time_found = True; is_time_line = True
                elif re.match(r'^[\d\.\s]+$', current_line):
                    slots = re.findall(r'\d+', current_line)
                    processed_slots = []; valid_time_line_sub = False
                    for s in slots:
                        try:
                            num = int(s); internal_value = -1
                            if 12 <= num <= 23: internal_value = num
                            elif num == 24: internal_value = 100
                            elif 0 <= num <= 11: internal_value = num + 100
                            if internal_value != -1: processed_slots.append(internal_value); valid_time_line_sub = True
                        except ValueError: pass
                    if valid_time_line_sub:
                        processed_slots.sort(); time_slots_str = ".".join(map(str, processed_slots)); time_found = True; is_time_line = True
                    else: time_slots_str = ""
                if is_time_line:
                    contains_time_this_line = True
                    if re.match(time_only_pattern, current_line):
                        is_only_time = True

            # --- Check Size ---
            local_size_match = re.search(size_pattern_for_match, current_line)
            if local_size_match:
                contains_size_this_line = True
                local_size_match_obj = local_size_match # Store match object
                if not size_found: # Store globally if first time
                    try: height = int(local_size_match.group(1))
                    except ValueError: pass
                    try: weight = int(local_size_match.group(2))
                    except ValueError: pass
                    cup = local_size_match.group(3).strip()
                    size_found = True
                if re.match(size_only_pattern, current_line):
                    is_only_size = True

            # --- Alias Check Removed ---

            # --- Decide if line contributes to Introduction ---
            # Now, only exclude lines that are purely time or purely size
            is_purely_structural_line = is_only_time or is_only_size

            if not is_purely_structural_line:
                # This line contains introduction text, potentially mixed with size.
                intro_text_candidate = current_line

                # Remove the matched *size* part if it was found ON THIS LINE and mixed with intro
                if contains_size_this_line and local_size_match_obj and not is_only_size:
                    intro_text_candidate = intro_text_candidate.replace(local_size_match_obj.group(0), '')

                # Clean up remaining whitespace and artifacts like empty brackets
                intro_text_candidate = intro_text_candidate.strip()
                intro_text_candidate = re.sub(r'\(\s*\)', '', intro_text_candidate) # Remove ()
                intro_text_candidate = re.sub(r'ï¼ˆ\s*ï¼‰', '', intro_text_candidate) # Remove ï¼ˆï¼‰
                intro_text_candidate = re.sub(r'\(\s+\)', '', intro_text_candidate) # Remove ( )
                intro_text_candidate = re.sub(r'ï¼ˆ\s+ï¼‰', '', intro_text_candidate) # Remove ï¼ˆ ï¼‰
                # *** REMOVED the lines that removed leading/trailing brackets unconditionally ***
                intro_text_candidate = intro_text_candidate.strip() # Strip again after potential removals


                # Add to introduction list if there's meaningful text left
                if intro_text_candidate:
                    other_lines.append(intro_text_candidate)


        # 3. Finalize and Return
        full_introduction = "\n".join(other_lines).strip()

        # Always return alias_suggestion as None for Aibao format now
        return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                'alias_suggestion': None, # Explicitly None
                'height': height, 'weight': weight,
                'cup': cup, 'introduction': full_introduction,
                'time_slots': time_slots_str}

    except Exception as e:
        logger.error(f"Error processing Aibao block: {block_lines}", exc_info=True)
        return None


# ============================================================
# --- *** å‡½æ•¸ 7: è§£ææ–°çš„ "å«é¦™é¤¨" æ ¼å¼ (æ ¼å¼ H - Hanxiang) *** ---
# ============================================================
def parse_hanxiang_schedule(text):
    """
    è§£æ "å«é¦™é¤¨" æ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ã€‚
    ä½¿ç”¨èˆ‡ Aibao é¡ä¼¼çš„å¥å£¯å€å¡Šåˆ†å‰²é‚è¼¯ã€‚
    """
    results = []
    lines = text.strip().split('\n')
    if not lines:
        return results

    # å«é¦™å€å¡Šé–‹å§‹æ¨¡å¼ï¼š(æ•¸å­—) æˆ– ğŸ†•(æ•¸å­—)ï¼Œè€ƒæ…®å‰å¾Œç©ºæ ¼å’Œå…¨åŠå½¢æ‹¬è™Ÿ
    block_start_pattern = r'^\s*(?:ğŸ†•)?\s*[\(ï¼ˆ]\s*\d+\s*[\)ï¼‰]'
    start_indices = []

    # 1. æ‰¾åˆ°æ‰€æœ‰å€å¡Šé–‹å§‹è¡Œçš„ç´¢å¼•
    for i, line in enumerate(lines):
        line_strip = line.strip()
        if not line_strip: continue
        if re.match(block_start_pattern, line_strip):
            start_indices.append(i)

    if not start_indices:
        logger.error("Hanxiang Parser: No block start lines found.")
        return results

    # 2. æ ¹æ“šé–‹å§‹è¡Œç´¢å¼•åˆ†å‰²å€å¡Š
    num_blocks = len(start_indices)
    for i in range(num_blocks):
        start_index = start_indices[i]
        end_index = start_indices[i+1] if (i + 1) < num_blocks else len(lines)
        current_block_lines = [lines[j] for j in range(start_index, end_index)]
        current_block_lines_cleaned = [line for line in current_block_lines if line.strip()]

        if current_block_lines_cleaned:
            parsed = process_hanxiang_block(current_block_lines_cleaned) # <--- èª¿ç”¨å«é¦™é¤¨çš„è™•ç†å‡½æ•¸
            if parsed:
                results.append(parsed)
            else:
                logger.warning(f"Hanxiang Parser: Failed to process block starting at line {start_index+1}: {current_block_lines_cleaned[0] if current_block_lines_cleaned else 'EMPTY'}")
        else:
            logger.debug(f"Hanxiang Parser: Skipping empty block found between lines {start_index} and {end_index}")

    return results

# --- process_hanxiang_block å‡½æ•¸ (ä¿®æ­£ç‰ˆï¼šä¿ç•™ â—†) ---
def process_hanxiang_block(block_lines):
    """è™•ç†å–®å€‹ "å«é¦™é¤¨" æ ¼å¼çš„ç¾å®¹å¸«å€å¡Šï¼ˆä¿®æ­£ç‰ˆï¼šä¿ç•™ â—†ï¼‰"""
    if not block_lines or len(block_lines) < 2: # è‡³å°‘éœ€è¦ç¬¬ä¸€è¡Œå’Œæœ€å¾Œæ™‚æ®µè¡Œ
        logger.warning(f"Hanxiang Parser: Block too short or empty: {block_lines}")
        return None

    fee = None; name = None; original_name_text = ""; alias_suggestion = None
    time_slots_str = ""; height = None; weight = None; cup = None
    intro_lines = []

    # åˆ¥åæ¨¡å¼: (åœ°é» åå­—) e.g., (å¯¶å¯å¤¢ å°ç¾½), (ç´ç´„ ç§˜æ›¸)
    alias_pattern = r'[\(ï¼ˆ]([\u4e00-\u9fa5\w]+\s+[^ï¼‰\)]+)[\)ï¼‰]'
    # èº«ææ¨¡å¼: XXX/XX/X æˆ– XXX.XX.X (å…è¨±ç©ºæ ¼å’Œæ‹¬è™Ÿ)
    size_pattern = r'\(?\s*(\d{3})\s*[./]\s*(\d{2,3})\s*[./]\s*([A-Za-z\+\(\)]+)\s*\)?' # åŠ å…¥å°æ‹¬è™Ÿçš„å…¼å®¹æ€§

    try:
        # 1. Process First Line (Fee, Name, Size, Alias)
        first_line = block_lines[0].strip()
        original_name_text = first_line

        fee_match = re.search(r'[\(ï¼ˆ]\s*(\d+)\s*[\)ï¼‰]', first_line)
        if fee_match:
            try: fee = int(fee_match.group(1)) * 100
            except ValueError: logger.warning(f"Hanxiang Parser: Cannot parse fee '{fee_match.group(1)}' from '{first_line}'")

        # Extract content after fee and potential ğŸ†• tag
        content_after_fee = re.sub(r'^\s*(?:ğŸ†•)?\s*[\(ï¼ˆ]\s*\d+\s*[\)ï¼‰]\s*', '', first_line).strip()

        # Try to extract alias from the end first
        alias_match = re.search(alias_pattern + r'\s*$', content_after_fee)
        name_and_size_part = content_after_fee # Default
        if alias_match:
            alias_full_text = alias_match.group(1).strip()
            parts = alias_full_text.split(maxsplit=1)
            if len(parts) == 2:
                 known_prefixes = ["å¯¶å¯å¤¢", "ç´ç´„", "èŠ¯è‹‘", "85"] # å¯æ“´å±•
                 if parts[0] in known_prefixes: alias_suggestion = parts[1]
                 else: alias_suggestion = parts[1] # Assume second part is alias name
            else: alias_suggestion = alias_full_text
            name_and_size_part = content_after_fee[:alias_match.start()].strip()

        # Try to extract size from the remaining part
        size_match = re.search(size_pattern, name_and_size_part)
        name_part = name_and_size_part # Default
        if size_match:
            try: height = int(size_match.group(1))
            except ValueError: pass
            try: weight = int(size_match.group(2))
            except ValueError: pass
            cup_raw = size_match.group(3).strip(); cup = re.sub(r'[\(\)]', '', cup_raw) # Clean brackets from cup
            # Remove size part to get name
            name_part = name_and_size_part[:size_match.start()].strip() + name_and_size_part[size_match.end():].strip()
            name_part = name_part.strip() # Clean spaces left

        # Clean name: remove trailing non-word characters (like potential emojis)
        name = re.sub(r'[^\w\s]+$', '', name_part).strip()

        if not name:
             logger.warning(f"Hanxiang Parser: Could not parse name from first line: '{first_line}' (after processing fee/alias/size)")

        # 2. Process Middle Lines (Introduction)
        # Iterate from the second line up to the second-to-last line
        for i in range(1, len(block_lines) - 1):
            line = block_lines[i].strip() # Strip surrounding whitespace only
            if line:
                # Directly append the stripped line, keeping the leading â—†
                intro_lines.append(line) # *** Keep the line as is ***

        # 3. Process Last Line (Time)
        last_line = block_lines[-1].strip()
        if 'ğŸˆµ' in last_line:
            time_slots_str = "é ç´„æ»¿"
        elif re.match(r'^[\d\.\s]+$', last_line): # Check if it looks like time slots
            slots = re.findall(r'\d+', last_line)
            processed_slots = []
            valid_time_line_last = False
            for s in slots:
                try:
                    num = int(s); internal_value = -1
                    if 12 <= num <= 23: internal_value = num
                    elif num == 24: internal_value = 100
                    elif 0 <= num <= 11: internal_value = num + 100
                    if internal_value != -1: processed_slots.append(internal_value); valid_time_line_last = True
                except ValueError: pass
            if valid_time_line_last:
                 processed_slots.sort(); time_slots_str = ".".join(map(str, processed_slots))
            else: time_slots_str = "" # If parsing fails, set to empty
        else:
            time_slots_str = "" # If last line is not recognized as time, set to empty
            logger.warning(f"Hanxiang Parser: Last line not recognized as time: '{last_line}'")
            # Optionally, add the last line to intro if it wasn't time?
            intro_lines.append(last_line) # Append directly without lstrip

        # 4. Finalize and Return
        full_introduction = "\n".join(intro_lines).strip()

        return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                'alias_suggestion': alias_suggestion, # Hanxiang has aliases
                'height': height, 'weight': weight,
                'cup': cup, 'introduction': full_introduction,
                'time_slots': time_slots_str}

    except Exception as e:
        logger.error(f"Error processing Hanxiang block: {block_lines}", exc_info=True)
        return None


# ============================================================
# --- *** å‡½æ•¸ 8: è§£ææ–°çš„ "æ½˜æœµæ‹‰" æ ¼å¼ (æ ¼å¼ P - Pandora) *** ---
# ============================================================
def parse_pandora_schedule(text):
    """
    è§£æ "æ½˜æœµæ‹‰" æ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ã€‚
    ä½¿ç”¨èˆ‡ Aibao/Hanxiang é¡ä¼¼çš„å¥å£¯å€å¡Šåˆ†å‰²é‚è¼¯ã€‚
    """
    results = []
    lines = text.strip().split('\n')
    if not lines:
        return results

    # æ½˜æœµæ‹‰å€å¡Šé–‹å§‹æ¨¡å¼ï¼šã€æ•¸å­—ã€‘ï¼Œå‰é¢å¯èƒ½æœ‰ emoji
    # Allow potential emojis before the block start pattern
    block_start_pattern = r'^\s*(?:[\U0001F300-\U0001FAFF\s]+)?\s*ã€\s*\d+\s*ã€‘' # Allow emojis/spaces before ã€ã€‘
    start_indices = []

    # 1. æ‰¾åˆ°æ‰€æœ‰å€å¡Šé–‹å§‹è¡Œçš„ç´¢å¼•
    for i, line in enumerate(lines):
        line_strip = line.strip()
        if not line_strip: continue
        if re.match(block_start_pattern, line_strip):
            start_indices.append(i)
        # Handle edge case where a block might start without the initial emoji line becoming intro
        elif i > 0 and re.match(r'^\s*ã€\s*\d+\s*ã€‘', line_strip) and not re.match(block_start_pattern, lines[i-1].strip()):
             # If this line starts with ã€ã€‘ but the previous wasn't a start, consider this a start
             start_indices.append(i)


    if not start_indices:
        logger.error("Pandora Parser: No block start lines found using pattern: %s", block_start_pattern)
        return results # Return empty if no blocks found

    # *** REMOVED the faulty refinement logic ***

    # 2. æ ¹æ“šé–‹å§‹è¡Œç´¢å¼•åˆ†å‰²å€å¡Š
    num_blocks = len(start_indices)
    for i in range(num_blocks):
        start_index = start_indices[i]
        end_index = start_indices[i+1] if (i + 1) < num_blocks else len(lines)
        current_block_lines = [lines[j] for j in range(start_index, end_index)]
        current_block_lines_cleaned = [line for line in current_block_lines if line.strip()]

        if current_block_lines_cleaned:
            parsed = process_pandora_block(current_block_lines_cleaned) # <--- èª¿ç”¨æ½˜æœµæ‹‰çš„è™•ç†å‡½æ•¸
            if parsed:
                results.append(parsed)
            else:
                logger.warning(f"Pandora Parser: Failed to process block starting at line {start_index+1}: {current_block_lines_cleaned[0] if current_block_lines_cleaned else 'EMPTY'}")
        else:
            logger.debug(f"Pandora Parser: Skipping empty block found between lines {start_index} and {end_index}")

    return results

# --- process_pandora_block å‡½æ•¸ (v7: å†æ¬¡ä¿®æ­£åå­—æ¸…ç†) ---
def process_pandora_block(block_lines):
    """è™•ç†å–®å€‹ "æ½˜æœµæ‹‰" æ ¼å¼çš„ç¾å®¹å¸«å€å¡Š (v7: å†æ¬¡ä¿®æ­£åå­—æ¸…ç†)"""
    if not block_lines or len(block_lines) < 2: # Need at least first line and time line
        logger.warning(f"Pandora Parser: Block too short or empty: {block_lines}")
        return None

    fee = None; name = None; original_name_text = ""; alias_suggestion = None
    time_slots_str = ""; height = None; weight = None; cup = None
    potential_intro_parts = [] # Collect potential intro fragments

    # Patterns
    size_pattern = r'\(?\s*(\d{3})\s*[./\s]\s*(\d{2,3})\s*[./\s]\s*([A-Za-z\+\(\)]+)\s*\)?'
    specific_alias_pattern = r'[\(ï¼ˆ](?:(åŸ)\s*|([\u4e00-\u9fa5\w]+)\s+)([^ï¼‰\)]+)[\)ï¼‰]'
    desc_pattern = r'<([^>]+)>'
    service_tag_pattern = r'ç´„\s*(\([\w\s]+\)|\ï¼ˆ[\w\s]+\ï¼‰)(\s*\([\w\s]+\)|\s*ï¼ˆ[\w\s]+\ï¼‰)*'
    emoji_placeholder_pattern = r'[\(ï¼ˆ]\s*emoji\s*[\)ï¼‰]' # For cleaning like (emoji)
    # General bracket pattern for cleaning name part, including specific cases like (v)(i)(p)
    general_bracket_pattern_for_name_cleaning = r'\s*[\(ï¼ˆ][^)ï¼‰>]*[\)ï¼‰]\s*'


    found_size_str = None
    found_alias_str = None

    try:
        # 1. Process First Line - Get Fee and Initial Content
        first_line = block_lines[0].strip(); original_name_text = first_line

        fee_match = re.search(r'ã€\s*(\d+)\s*ã€‘', first_line)
        if fee_match:
            try: fee = int(fee_match.group(1)) * 100
            except ValueError: logger.warning(f"Pandora Parser: Cannot parse fee '{fee_match.group(1)}' from '{first_line}'")

        content_after_fee = re.sub(r'^\s*(?:[\U0001F300-\U0001FAFF\s]+)?\s*ã€\s*\d+\s*ã€‘\s*', '', first_line).strip()

        # --- v7 Name Extraction: Match initial CJK/Letters/Digits ---
        name_part = ""
        remainder_first_line = content_after_fee # Default if no name match
        # Match initial sequence of CJK chars, English letters, OR digits
        name_match = re.match(r'^([\u4e00-\u9fffA-Za-z0-9]+)', content_after_fee)
        if name_match:
             name_part = name_match.group(1).strip() # Extract the core name part
             remainder_first_line = content_after_fee[name_match.end():].strip() # Get everything after
        else: # Fallback if name doesn't start with expected characters
             logger.warning(f"Pandora Parser: Name doesn't start with expected chars in: '{content_after_fee}'. Trying split by space.")
             parts = content_after_fee.split(maxsplit=1)
             if parts:
                 name_part = parts[0] # Assume first part is name
                 if len(parts) > 1: remainder_first_line = parts[1]
             else: # If content_after_fee was empty or un-splittable
                  name_part = ""
                  remainder_first_line = content_after_fee


        # Clean the extracted name_part vigorously
        name = name_part.strip()
        name = re.sub(r'[\U0001F300-\U0001FAFF]', '', name).strip() # Clean standard emojis
        # *** Clean ANY bracketed content from the potential name part ***
        name = re.sub(general_bracket_pattern_for_name_cleaning, '', name).strip()
        name = re.sub(r'[^\w]+$', '', name).strip() # Clean trailing non-word chars

        if not name:
             logger.error(f"Pandora Parser: Failed to extract name for block: '{first_line}'")
             # Consider fallback using alias later if needed

        # 2. Process Last Line - Get Time
        last_line = block_lines[-1].strip()
        time_slots_str = ""
        last_line_is_time = False
        trailing_intro_last_line = ""

        if last_line.startswith('ğŸˆ³') or last_line.startswith('ğŸˆµ'):
            last_line_is_time = True
            time_marker = 'ğŸˆ³' if last_line.startswith('ğŸˆ³') else 'ğŸˆµ'
            content_after_marker = last_line.replace(time_marker, '', 1).strip()
            if time_marker == 'ğŸˆµ':
                time_slots_str = "é ç´„æ»¿"
                trailing_intro_last_line = content_after_marker
            else: # Starts with ğŸˆ³
                time_match_last = re.match(r'([\d\.\s]+)', content_after_marker)
                if time_match_last:
                    time_part = time_match_last.group(1)
                    slots = re.findall(r'\d+', time_part)
                    processed_slots = []; valid_time_line_last = False
                    for s in slots:
                         try:
                             num = int(s); internal_value = -1
                             if 12 <= num <= 23: internal_value = num
                             elif num == 24: internal_value = 100
                             elif 0 <= num <= 11: internal_value = num + 100
                             if internal_value != -1: processed_slots.append(internal_value); valid_time_line_last = True
                         except ValueError: pass
                    if valid_time_line_last:
                         processed_slots.sort(); time_slots_str = ".".join(map(str, processed_slots))
                    trailing_intro_last_line = content_after_marker[time_match_last.end():].strip()
                else: # Starts with ğŸˆ³ but no numbers
                    trailing_intro_last_line = content_after_marker
                    logger.warning(f"Pandora Parser: Last line starts with ğŸˆ³ but no valid time found: '{last_line}'")
        else: # Last line not time
            logger.warning(f"Pandora Parser: Last line not recognized as time line: '{last_line}'")


        # 3. Collect All Potential Intro Lines (including remainder of first line)
        all_potential_intro_text = remainder_first_line + "\n" + "\n".join(block_lines[1:-1])
        if not last_line_is_time: all_potential_intro_text += "\n" + last_line
        elif trailing_intro_last_line: all_potential_intro_text += "\n" + trailing_intro_last_line
        all_potential_intro_text = all_potential_intro_text.strip()

        # 4. Globally Find First Size and Specific Alias within potential intro text
        size_match_global = re.search(size_pattern, all_potential_intro_text)
        if size_match_global:
             try: height = int(size_match_global.group(1))
             except ValueError: pass
             try: weight = int(size_match_global.group(2))
             except ValueError: pass
             cup_raw = size_match_global.group(3).strip(); cup = re.sub(r'[\(\)]', '', cup_raw)
             found_size_str = size_match_global.group(0) # Store the exact string found

        alias_match_global = re.search(specific_alias_pattern, all_potential_intro_text)
        if alias_match_global:
            is_original = alias_match_global.group(1)
            location = alias_match_global.group(2)
            alias_name_part = alias_match_global.group(3).strip()
            if is_original or (location and location in ["èŠ¯è‹‘", "å«é¦™", "å¯¶å¯å¤¢", "ç´ç´„", "85"]):
                 alias_suggestion = alias_name_part
                 found_alias_str = alias_match_global.group(0) # Store the exact alias string found


        # 5. Build Final Introduction (Cleaned)
        final_intro_text = all_potential_intro_text

        # Remove the globally found size and alias strings
        try:
            if found_size_str: final_intro_text = final_intro_text.replace(found_size_str, '')
        except TypeError: pass # Ignore if None
        try:
            if found_alias_str: final_intro_text = final_intro_text.replace(found_alias_str, '')
        except TypeError: pass # Ignore if None


        # Process description tags <...>
        processed_intro_parts = []
        temp_intro_text = ""
        # Split carefully, handle potential nested or broken tags less likely now
        parts = re.split(r'(<[^>]+>)', final_intro_text)
        for part in parts:
            if not part: continue
            desc_match_part = re.match(r'<([^>]+)>', part)
            if desc_match_part:
                desc_content = desc_match_part.group(1).strip()
                if desc_content:
                    if temp_intro_text: processed_intro_parts.append(temp_intro_text.strip())
                    temp_intro_text = "" # Reset
                    processed_intro_parts.append(desc_content)
            else:
                temp_intro_text += part
        if temp_intro_text: processed_intro_parts.append(temp_intro_text.strip())

        # Rebuild intro, clean emojis and empty brackets/lines
        cleaned_intro_lines = []
        emoji_placeholder_pattern_intro = r'[\(ï¼ˆ]\s*emoji\s*[\)ï¼‰]' # Specific pattern for intro cleaning
        for line in processed_intro_parts:
             cleaned_line = re.sub(r'[\U0001F300-\U0001FAFF]', '', line).strip()
             cleaned_line = re.sub(emoji_placeholder_pattern_intro, '', cleaned_line, flags=re.IGNORECASE).strip()
             cleaned_line = re.sub(r'\(\s*\)|ï¼ˆ\s*ï¼‰|\(\s+\)|ï¼ˆ\s+ï¼‰', '', cleaned_line).strip()
             if cleaned_line:
                 # Remove potential remaining "ç´„ (...)" tags if they weren't cleaned before
                 cleaned_line = re.sub(service_tag_pattern, '', cleaned_line).strip()
                 # Remove potential vip tags like (v)(i)(p) from intro text
                 cleaned_line = re.sub(r'(\([a-zA-Z]\))+', '', cleaned_line).strip()
                 if cleaned_line:
                     cleaned_intro_lines.append(cleaned_line)

        full_introduction = "\n".join(cleaned_intro_lines)


        # Fallback for name if still not found
        if not name and alias_suggestion:
             name = alias_suggestion
             alias_suggestion = None # Used as name, so clear suggestion


        # Return dictionary, ensuring name exists if possible
        if name:
            return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                    'alias_suggestion': alias_suggestion,
                    'height': height, 'weight': weight,
                    'cup': cup, 'introduction': full_introduction,
                    'time_slots': time_slots_str}
        else:
             logger.warning(f"Pandora Parser: Failed to determine name for block starting with: '{original_name_text}'")
             return None

    except Exception as e:
        logger.error(f"Error processing Pandora block: {block_lines}", exc_info=True)
        return None


# ============================================================
# --- *** å‡½æ•¸ 9: è§£ææ–°çš„ "ç‹å¦ƒé¤¨" æ ¼å¼ (æ ¼å¼ W - Wangfei) *** ---
# ============================================================
def parse_wangfei_schedule(text):
    """
    è§£æ "ç‹å¦ƒé¤¨" æ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ã€‚
    è·³éé–‹é ­çš„æ³¨æ„äº‹é …ï¼Œç„¶å¾Œä½¿ç”¨å¥å£¯çš„å€å¡Šåˆ†å‰²ã€‚
    """
    results = []
    lines = text.strip().split('\n')
    if not lines: return results

    start_parsing_index = 0
    # ç‹å¦ƒå€å¡Šé–‹å§‹æ¨¡å¼: åå­—(éç©ºæ ¼é–‹é ­) + ç©ºæ ¼ + 2ä½æ•¸å­—è²»ç”¨
    block_start_pattern = r'^\s*([^\s]+(?:\s+[^\s]+)*?)\s+(\d{2})\s*$' # Allow spaces in name
    # æ‰¾åˆ°ç¬¬ä¸€å€‹ç¬¦åˆå€å¡Šé–‹å§‹æ¨¡å¼çš„è¡Œï¼Œä¹‹å‰çš„éƒ½è·³é
    for i, line in enumerate(lines):
        line_strip = line.strip()
        if re.match(block_start_pattern, line_strip):
            start_parsing_index = i
            logger.info(f"Wangfei Parser: Found first block start at line {i+1}: '{line_strip}'")
            break
    else: # No block start found at all
        logger.error("Wangfei Parser: No block start pattern found in the entire text.")
        return results

    # Find all block start indices from the parsing start point
    start_indices = []
    for i in range(start_parsing_index, len(lines)):
        line_strip = lines[i].strip()
        if not line_strip: continue
        if re.match(block_start_pattern, line_strip):
            start_indices.append(i)

    if not start_indices:
         logger.error("Wangfei Parser: No block start indices identified after skipping header.")
         return results

    # Split blocks based on indices
    num_blocks = len(start_indices)
    for i in range(num_blocks):
        start_index = start_indices[i]
        end_index = start_indices[i+1] if (i + 1) < num_blocks else len(lines)
        current_block_lines = [lines[j] for j in range(start_index, end_index)]
        current_block_lines_cleaned = [line for line in current_block_lines if line.strip()]

        if current_block_lines_cleaned:
            parsed = process_wangfei_block(current_block_lines_cleaned)
            if parsed:
                results.append(parsed)
            else:
                logger.warning(f"Wangfei Parser: Failed to process block starting at line {start_index+1}: {current_block_lines_cleaned[0] if current_block_lines_cleaned else 'EMPTY'}")
        else:
            logger.debug(f"Wangfei Parser: Skipping empty block found between lines {start_index} and {end_index}")

    return results


def process_wangfei_block(block_lines):
    """è™•ç†å–®å€‹ "ç‹å¦ƒé¤¨" æ ¼å¼çš„ç¾å®¹å¸«å€å¡Š"""
    if not block_lines or len(block_lines) < 2: # Name/Fee line + Time line minimum
        logger.warning(f"Wangfei Parser: Block too short or empty: {block_lines}")
        return None

    fee = None; name = None; original_name_text = ""; alias_suggestion = None # No alias expected
    time_slots_str = ""; height = None; weight = None; cup = None # No size expected
    intro_lines = []

    try:
        # 1. Process First Line (Name Fee)
        first_line = block_lines[0].strip()
        original_name_text = first_line # Record the raw first line

        # Match name (non-space chars, allowing spaces within name) followed by space(s) and 2 digits fee
        match = re.match(r'^(.+?)\s+(\d{2})\s*$', first_line) # Use non-greedy match for name
        if match:
            name = match.group(1).strip()
            try:
                fee = int(match.group(2)) * 100
            except ValueError:
                 logger.warning(f"Wangfei Parser: Cannot parse fee '{match.group(2)}' from '{first_line}'")
        else:
            logger.warning(f"Wangfei Parser: Could not parse name/fee from first line: '{first_line}'")
            # Fallback: assume everything before last space(s) + digits is name
            parts = first_line.rsplit(maxsplit=1)
            if len(parts) == 2 and parts[1].isdigit() and len(parts[1]) == 2:
                 name = parts[0].strip()
                 try: fee = int(parts[1]) * 100
                 except ValueError: pass
                 logger.info(f"Wangfei Parser: Using fallback name/fee parsing for '{first_line}'")
            elif first_line: # If no fee found, maybe just name?
                 name = first_line
                 logger.warning(f"Wangfei Parser: Only name found on first line? '{first_line}'")
            else:
                 return None # Cannot proceed without a name

        # 2. Process Middle Lines (Introduction)
        # Lines between first and last are intro
        for i in range(1, len(block_lines) - 1):
            line = block_lines[i].strip()
            if line:
                intro_lines.append(line)

        # 3. Process Last Line (Time)
        last_line = block_lines[-1].strip()
        if last_line.startswith('â°'):
            time_info = last_line.replace('â°', '').strip()
            if 'ğŸˆµ' in time_info: # Handle cases like â°ğŸˆµ
                time_slots_str = "é ç´„æ»¿"
            elif not time_info: # Handle empty â°
                 time_slots_str = ""
            else:
                # Time slots separated by 'ã€'
                slots = re.findall(r'\d+', time_info) # Find all numbers
                processed_slots = []
                valid_time_line_last = False
                for s in slots:
                    try:
                        num = int(s); internal_value = -1
                        if 12 <= num <= 23: internal_value = num
                        elif num == 24: internal_value = 100
                        elif 0 <= num <= 11: internal_value = num + 100
                        if internal_value != -1: processed_slots.append(internal_value); valid_time_line_last = True
                    except ValueError: pass
                if valid_time_line_last:
                    processed_slots.sort(); time_slots_str = ".".join(map(str, processed_slots))
                else: time_slots_str = "" # Parsing failed
        else:
             logger.warning(f"Wangfei Parser: Last line does not start with â°: '{last_line}'")
             # Treat as intro?
             intro_lines.append(last_line)


        # 4. Finalize and Return
        full_introduction = "\n".join(intro_lines).strip()

        # Wangfei format doesn't have alias, height, weight, cup
        return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                'alias_suggestion': None,
                'height': None, 'weight': None,
                'cup': None, 'introduction': full_introduction,
                'time_slots': time_slots_str}

    except Exception as e:
        logger.error(f"Error processing Wangfei block: {block_lines}", exc_info=True)
        return None

# ============================================================
# --- *** å‡½æ•¸ 10: è§£ææ–°çš„ "æ¨‚é‘½é¤¨" æ ¼å¼ (æ ¼å¼ L - Lezuan) *** ---
# ============================================================
def parse_lezuan_schedule(text):
    """
    è§£æ "æ¨‚é‘½é¤¨" æ ¼å¼çš„ LINE æ–‡å­—ç­è¡¨ã€‚
    """
    results = []
    lines = text.strip().split('\n')
    if not lines: return results

    # æ¨‚é‘½å€å¡Šé–‹å§‹æ¨¡å¼: åå­— (å¯èƒ½å«ç©ºæ ¼) + ç©ºæ ¼ + (è²»ç”¨)å–®
    # Fee part: (digit/word)(digit)å–® e.g., (2)(9)å–® or (three)(3)å–®
    block_start_pattern = r'^\s*([^\s\(ï¼ˆ]+(?:\s+[^\s\(ï¼ˆ]+)*?)\s+[\(ï¼ˆ](?:[\w\d\u4e00-\u9fa5]+)[\)ï¼‰][\(ï¼ˆ]\d+[\)ï¼‰]å–®'
    start_indices = []

    # 1. Find all block start indices
    for i, line in enumerate(lines):
        line_strip = line.strip()
        if not line_strip: continue
        if re.match(block_start_pattern, line_strip):
            start_indices.append(i)

    if not start_indices:
        logger.error("Lezuan Parser: No block start lines found using pattern: %s", block_start_pattern)
        return results

    # 2. Split blocks based on indices
    num_blocks = len(start_indices)
    for i in range(num_blocks):
        start_index = start_indices[i]
        end_index = start_indices[i+1] if (i + 1) < num_blocks else len(lines)
        current_block_lines = [lines[j] for j in range(start_index, end_index)]
        current_block_lines_cleaned = [line for line in current_block_lines if line.strip()]

        if current_block_lines_cleaned:
            parsed = process_lezuan_block(current_block_lines_cleaned)
            if parsed:
                results.append(parsed)
            else:
                logger.warning(f"Lezuan Parser: Failed to process block starting at line {start_index+1}: {current_block_lines_cleaned[0] if current_block_lines_cleaned else 'EMPTY'}")
        else:
             logger.debug(f"Lezuan Parser: Skipping empty block found between lines {start_index} and {end_index}")

    return results

def process_lezuan_block(block_lines):
    """è™•ç†å–®å€‹ "æ¨‚é‘½é¤¨" æ ¼å¼çš„ç¾å®¹å¸«å€å¡Š"""
    if len(block_lines) < 2: # Need at least Name/Fee line and Time line
        logger.warning(f"Lezuan Parser: Block too short: {block_lines}")
        return None

    fee = None; name = None; original_name_text = ""; alias_suggestion = None
    time_slots_str = ""; height = None; weight = None; cup = None
    intro_lines = []

    # Pattern to extract name and fee parts from the first line
    first_line_pattern = r'^\s*(.+?)\s+[\(ï¼ˆ]([\w\d\u4e00-\u9fa5]+)[\)ï¼‰][\(ï¼ˆ](\d+)[\)ï¼‰]å–®'
    # Pattern for the time line (flexible with emoji)
    time_line_pattern = r'^\s*(?:\(clock\)|â°|ğŸ•›|ğŸ•|ğŸ•‘|ğŸ•’|ğŸ•“|ğŸ•”|ğŸ••|ğŸ•–|ğŸ•—|ğŸ•˜|ğŸ•™|ğŸ•š|ğŸ•§)\s*(.*)'


    try:
        # 1. Process First Line (Name, Fee)
        first_line = block_lines[0].strip()
        original_name_text = first_line # Keep raw line
        match = re.match(first_line_pattern, first_line)
        if match:
            name = match.group(1).strip()
            fee_part1_str = match.group(2).lower() # e.g., "2" or "three" or "ä¸‰"
            fee_part2_str = match.group(3) # e.g., "9" or "3"

            try:
                # Convert first part (word or digit)
                digit1 = -1
                if fee_part1_str.isdigit():
                    digit1 = int(fee_part1_str)
                elif fee_part1_str in WORD_TO_DIGIT:
                    digit1 = WORD_TO_DIGIT[fee_part1_str]

                # Convert second part (must be digit)
                digit2 = int(fee_part2_str)

                if 0 <= digit1 <= 9 and 0 <= digit2 <= 9: # Basic validation
                    fee = (digit1 * 10 + digit2) * 100
                else:
                     logger.warning(f"Lezuan Parser: Invalid fee digits parsed ({digit1}, {digit2}) from '{first_line}'")
            except (ValueError, KeyError) as e:
                logger.warning(f"Lezuan Parser: Error parsing fee parts ('{fee_part1_str}', '{fee_part2_str}') from '{first_line}': {e}")
        else:
            logger.error(f"Lezuan Parser: Failed to match name/fee pattern on first line: '{first_line}'")
            # Fallback: Try to take the first word as name?
            parts = first_line.split()
            if parts: name = parts[0]
            else: return None # Cannot proceed

        # 2. Process Second Line (Time)
        time_line_match = re.match(time_line_pattern, block_lines[1].strip())
        if time_line_match:
            time_info = time_line_match.group(1).strip()
            if 'ğŸˆµ' in time_info:
                time_slots_str = "é ç´„æ»¿"
            elif not time_info:
                time_slots_str = ""
            else:
                # Time slots separated by '.'
                slots = re.findall(r'\d+', time_info) # Find all numbers
                processed_slots = []; valid_time_line = False
                for s in slots:
                     try:
                         num = int(s); internal_value = -1
                         if 12 <= num <= 23: internal_value = num
                         elif num == 24: internal_value = 100
                         elif 0 <= num <= 11: internal_value = num + 100
                         if internal_value != -1: processed_slots.append(internal_value); valid_time_line = True
                     except ValueError: pass
                if valid_time_line:
                     processed_slots.sort(); time_slots_str = ".".join(map(str, processed_slots))
                else: time_slots_str = "" # Parsing failed
        else:
             logger.warning(f"Lezuan Parser: Second line does not match time pattern: '{block_lines[1].strip()}'")
             # If time is not on the second line, assume it's intro?
             intro_lines.append(block_lines[1].strip())


        # 3. Process Remaining Lines (Introduction)
        # Start from index 2 (third line)
        for i in range(2, len(block_lines)):
            line = block_lines[i].strip()
            if line:
                intro_lines.append(line)

        # 4. Finalize and Return
        full_introduction = "\n".join(intro_lines).strip()

        # Lezuan format doesn't have alias, height, weight, cup
        return {'parsed_fee': fee, 'name': name, 'original_name_text': original_name_text,
                'alias_suggestion': None,
                'height': None, 'weight': None,
                'cup': None, 'introduction': full_introduction,
                'time_slots': time_slots_str}

    except Exception as e:
        logger.error(f"Error processing Lezuan block: {block_lines}", exc_info=True)
        return None


# --- utils.py æ–‡ä»¶çµæŸ ---